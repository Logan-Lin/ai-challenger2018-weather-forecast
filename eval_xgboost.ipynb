{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "# from train_xgb import *\n",
    "from generate_set import *\n",
    "# from xgb_predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading netCDF4 file data/ai_challenger_wf2018_testb1_20180829-20181028.nc\n",
      "Loading station 90001\n",
      "Loading station 90002\n",
      "Loading station 90003\n",
      "Loading station 90004\n",
      "Loading station 90005\n",
      "Loading station 90006\n",
      "Loading station 90007\n",
      "Loading station 90008\n",
      "Loading station 90009\n",
      "Loading station 90010\n"
     ]
    }
   ],
   "source": [
    "t_raw = pd.read_pickle(os.path.join('dataframes', 'train_raw.pkl'))\n",
    "v_raw = pd.read_pickle(os.path.join('dataframes', 'validation_raw.pkl'))\n",
    "test_b1 = load_raw_file(os.path.join('data', 'ai_challenger_wf2018_testb1_20180829-20181028.nc'))\n",
    "a_raw = pd.concat([t_raw, v_raw, test_b1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('train_data', '1015_1115_2.pkl'), 'rb') as pickle_file:\n",
    "    restore = pickle.load(pickle_file)\n",
    "X = restore['X']\n",
    "Y = restore['Y']\n",
    "dates = restore['dates']\n",
    "\n",
    "with open(os.path.join('validation_data', '0928_1029_2.pkl'), 'rb') as pickle_file:\n",
    "    restore_va = pickle.load(pickle_file)\n",
    "X_va = restore_va['X']\n",
    "Y_va = restore_va['Y']\n",
    "dates_va = restore_va['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 1th day best parameters\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1cf56d2eb689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_best_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_va\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-ba80fa8dc1a4>\u001b[0m in \u001b[0;36mgen_best_parameters\u001b[0;34m(X, Y, X_va, Y_va)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing {}th day best parameters'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_eval_xgb_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mindex_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-9e09c58bc467>\u001b[0m in \u001b[0;36mtrain_eval_xgb_model\u001b[0;34m(X, Y, X_va, Y_va, column, predict_hour, output)\u001b[0m\n\u001b[1;32m     25\u001b[0m             xg_reg.fit(X_added, y_train, \n\u001b[1;32m     26\u001b[0m                        \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_va_added\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                        eval_metric='rmse', early_stopping_rounds=15)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#             xg_reg.fit(X_added, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#             xg_reg.fit(X, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/linyan_3.6/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[1;32m    322\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                               verbose_eval=verbose, xgb_model=xgb_model)\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/linyan_3.6/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/linyan_3.6/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda3/envs/linyan_3.6/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1021\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_parameters = gen_best_parameters(X, Y, X_va, Y_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('parameters', '1015_1115_3.param'), 'wb') as file:\n",
    "    pickle.dump(best_parameters, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_previous_to_X(X, prediction_list):\n",
    "    if len(prediction_list) == 0:\n",
    "        return X\n",
    "    for prediction in prediction_list:\n",
    "        prediction.index = X.index\n",
    "    predictions = pd.concat(prediction_list, axis=1)\n",
    "    predictions.columns = ['prediction_{}'.format(i) for i in range(predictions.shape[1])]\n",
    "    return pd.concat([X, predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cycle_to_X(X, raw, column, predict_hour, add_days, interval=1):\n",
    "    explain = pd.read_csv(os.path.join('data', 'explain.csv'), index_col=0).dropna(how='any', axis=1)\n",
    "    \n",
    "    def get_station_id(X):\n",
    "        station_list = []\n",
    "        for index, row in X.iterrows():\n",
    "            station_onehot = row[['station_{}'.format(i) for i in range(10)]]\n",
    "            station_id = int('900%02d' % int(np.sum([station_onehot[i] * (i+1) for i in range(10)])))\n",
    "            station_list.append(station_id)\n",
    "        return station_list\n",
    "\n",
    "    def normalize_single_column(df: pd.DataFrame, name) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Normalize data.\n",
    "        \"\"\"\n",
    "        result = pd.DataFrame(df, copy=True)\n",
    "        scope = explain.loc[name]['scope'][1:-1].split(',')\n",
    "        min_value = float(scope[0].strip())\n",
    "        max_value = float(scope[1].strip())\n",
    "\n",
    "        result[name] = (result[name] - min_value) / (max_value - min_value)\n",
    "        return result\n",
    "    \n",
    "    origin_dates = [pd.Timestamp.fromtimestamp(timestamp) - pd.Timedelta('8 hours') for timestamp in X['timestamp']]\n",
    "    station_list = get_station_id(X)\n",
    "    series_list = []\n",
    "    for day in range(add_days):\n",
    "        day = (day + 1) * interval\n",
    "        fetch_dates = pd.Series(origin_dates) - pd.Timedelta('{} days'.format(day))\n",
    "        series = pd.Series([raw.loc[(station_id, date, predict_hour + 4)][column] \n",
    "                            for (station_id, date) in zip(station_list, fetch_dates)])\n",
    "        series.name = column\n",
    "        series_list.append(series)\n",
    "    result = normalize_single_column(pd.DataFrame(series_list).T, column)\n",
    "    result.columns = ['{}_{}*{}days'.format(column, interval, i + 1) for i in range(add_days)]\n",
    "    return pd.concat([X, result], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_xgb_model(X, Y, X_va, Y_va, column, predict_hour, output=False):\n",
    "    \"\"\"\n",
    "    Evaluate one spot XGBoost model to test parameters.\n",
    "    \"\"\"\n",
    "#     y_train_list = [fetch_labels(i, column, Y) for i in range(predict_hour)]\n",
    "    y_train = fetch_labels(predict_hour, column, Y)\n",
    "     \n",
    "#     y_eval_list = [fetch_labels(i, column, Y_va) for i in range(predict_hour)]\n",
    "    y_eval = fetch_labels(predict_hour, column, Y_va)\n",
    "    \n",
    "    X_added = add_cycle_to_X(X, a_raw, column, predict_hour, 7)\n",
    "#     X_added = add_cycle_to_X(X_added, a_raw, column, predict_hour, 4, 7)\n",
    "    X_va_added = add_cycle_to_X(X_va, a_raw, column, predict_hour, 7)\n",
    "#     X_va_added = add_cycle_to_X(X_va_added, a_raw, column, predict_hour, 4, 7)\n",
    "    \n",
    "    rmse_list = []\n",
    "    for max_depth in range(3, 18, 1):\n",
    "        for min_child_weight in range(0, 12, 1):\n",
    "#             start = timeit.default_timer()\n",
    "            xg_reg = xgb.XGBRegressor(max_depth=max_depth, learning_rate=0.15, n_estimators=150, silent=True, \n",
    "                                      objective='reg:linear', booster='gbtree', n_jobs=47, alpha=10,\n",
    "                                      gamma=0, min_child_weight=min_child_weight, max_delta_step=0, subsample=0.9, \n",
    "                                      colsample_bytree=0.9, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, \n",
    "                                      scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None)\n",
    "            xg_reg.fit(X_added, y_train, \n",
    "                       eval_set=[(X_va_added, y_eval)], verbose=False, \n",
    "                       eval_metric='rmse', early_stopping_rounds=15)\n",
    "#             xg_reg.fit(X_added, y_train)\n",
    "#             xg_reg.fit(X, y_train)\n",
    "#             stop = timeit.default_timer()\n",
    "\n",
    "#             prediction = xg_reg.predict(add_previous_to_X(X_va, y_eval_list))\n",
    "            prediction = xg_reg.predict(X_va_added)\n",
    "#             prediction = xg_reg.predict(X_va)\n",
    "\n",
    "            eval_df = pd.DataFrame(y_eval, columns=[column])\n",
    "            eval_df = denormalize(eval_df)\n",
    "            pre_df = pd.DataFrame(prediction, columns=[column])\n",
    "            pre_df = denormalize(pre_df)\n",
    "            eval_df.columns = eval_df.columns + '_eval'\n",
    "            pre_df.columns = pre_df.columns + '_pre'\n",
    "            compare_df = pd.concat([eval_df, pre_df], axis=1)\n",
    "\n",
    "            rmse = sqrt(mean_squared_error(compare_df.iloc[:, 0], compare_df.iloc[:, 1]))\n",
    "            rmse_list.append([max_depth, min_child_weight, rmse])\n",
    "            if output:\n",
    "                print('{}-{}-{}'.format(max_depth, min_child_weight, rmse))\n",
    "    return pd.DataFrame(rmse_list, columns=['max_depth', 'min_child_weight', 'rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_best_parameters(X, Y, X_va, Y_va):\n",
    "    result_list = []\n",
    "    index_list = []\n",
    "    for hour in range(0, 33):\n",
    "        print('Testing {}th day best parameters'.format(hour+1))\n",
    "        for name in Y[0].columns:\n",
    "            result = train_eval_xgb_model(X, Y, X_va, Y_va, name, hour, False)\n",
    "            result = result.sort_values(by='rmse').iloc[0]\n",
    "            index_list.append((hour, name))\n",
    "            result_list.append(result)\n",
    "    best_parameters = pd.DataFrame(result_list, index=index_list)\n",
    "    return best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
