{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_raw = pd.read_pickle(os.path.join('dataframes', 'train_raw.pkl'))\n",
    "v_raw = pd.read_pickle(os.path.join('dataframes', 'validation_raw.pkl'))\n",
    "test_a1 = pd.read_pickle(os.path.join('dataframes', 'test_a1.pkl'))\n",
    "a_raw = pd.read_pickle(os.path.join('dataframes', 'all_raw.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan_with_m(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Use M data to fill all the NaNs in observation data.\n",
    "    \"\"\"\n",
    "    obs_columns = ['psur_obs', 't2m_obs', 'q2m_obs', 'rh2m_obs', 'w10m_obs', \n",
    "                   'd10m_obs', 'u10m_obs', 'v10m_obs', 'RAIN_obs']\n",
    "    m_columns = ['psfc_M', 't2m_M', 'q2m_M', 'rh2m_M', 'w10m_M', 'd10m_M',\n",
    "                'u10m_M', 'v10m_M', 'RAIN_M']\n",
    "    result = pd.DataFrame(df, copy=True)\n",
    "    for (obs_column, m_column) in zip(obs_columns, m_columns):\n",
    "        result[obs_column].fillna(result[m_column], inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_serial(station_id, end_date, df, prediction=False):\n",
    "    end_date = pd.Timestamp(end_date)\n",
    "    if prediction:\n",
    "        tolerate = -33\n",
    "    result = df.loc[station_id, end_date]\n",
    "    result = result.interpolate(method='linear', limit=2, limit_direction='both')\n",
    "    result = fill_nan_with_m(result)\n",
    "    if prediction:\n",
    "        assert ~result.iloc[:4].isnull().values.any()\n",
    "    else:\n",
    "        assert ~result.isnull().values.any()\n",
    "    day = 1\n",
    "    try:\n",
    "        while True:\n",
    "            to_append = df.loc[station_id, end_date - pd.DateOffset(days=day)].iloc[:24]\n",
    "            result = pd.concat([to_append, result]) \n",
    "            result = check_invalid(result)\n",
    "            result = result.interpolate(method='linear', limit=2, limit_direction='both')\n",
    "            result = result.fill_nan_with_m(result)\n",
    "            if prediction:\n",
    "                assert ~result.iloc[13:-33].isnull().values.any()\n",
    "            else:\n",
    "                assert ~result.iloc[13:].isnull().values.any()\n",
    "            day += 1\n",
    "    except AssertionError:\n",
    "        print('Reaching days with nan at', end_date - pd.DateOffset(days=day))\n",
    "        result = result.iloc[13 + 24:]\n",
    "        result = normalize(result)\n",
    "        result.index = range(result.shape[0])\n",
    "        return result.T\n",
    "    except KeyError:\n",
    "        print('Return without meeting any empty day.')\n",
    "        result = result.iloc[13:]\n",
    "        result = normalize(result)\n",
    "        result.index = range(result.shape[0])\n",
    "        return result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_serial_predict(df, late_date=None):\n",
    "    result_list = []\n",
    "    if last_date is None:\n",
    "        last_date = df.iloc[-1].name[1]\n",
    "    else:\n",
    "        last_date = pd.Timestamp(last_date)\n",
    "    for station in range(90001, 90011):\n",
    "        result_list.append(generate_serial(station, last_date, df, True).T.iloc[-108:].T)\n",
    "    return pd.concat(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_invalid(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check all values that exceeds valid scope and turn them into np.nan.\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame(df, copy=True)\n",
    "    for name in df.columns:\n",
    "        scope = explain.loc[name]['scope'][1:-1].split(',')\n",
    "        min_value = float(scope[0].strip())\n",
    "        max_value = float(scope[1].strip())\n",
    "        \n",
    "        result.loc[result[name] < min_value, name] = np.nan\n",
    "        result.loc[result[name] > max_value, name] = np.nan\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
